<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>tips on Brayden's Blog</title><link>/categories/tips/</link><description>Recent content in tips on Brayden's Blog</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Sat, 08 Jan 2022 00:00:00 +0000</lastBuildDate><atom:link href="/categories/tips/index.xml" rel="self" type="application/rss+xml"/><item><title>Headless vncserver with Container</title><link>/posts/headless_vncserver_with_container/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>/posts/headless_vncserver_with_container/</guid><description>Prerequisites Docker intalled, up and running Start the vncserver It&amp;rsquo;s quite straightforward to run the vncserver with container. Here we use the image from accetto.
docker run -d -p 5920:5901 -p 6901:6901 accetto/ubuntu-vnc-xfce-firefox-g3 Docker will pull the image if not found in the localhost.
Connect to the vncserver via vnc viewer Here I use realvnc viwer on windows, enter &amp;lt;IP@&amp;gt;:5920 to connect, and enter the password, &amp;ldquo;headless&amp;rdquo;.</description></item><item><title>Recover Ubuntu from initramfs error caused by improper shutdown</title><link>/posts/recover_ubuntu_from_initramfs_error/</link><pubDate>Tue, 04 Jan 2022 00:00:00 +0000</pubDate><guid>/posts/recover_ubuntu_from_initramfs_error/</guid><description>Issue description Following a force shutdown of the server, the system failed to boot with following message:
initramfs: waiting for /dev/mapper/ubuntu&amp;ndash;vg-ubuntu&amp;ndash;lv to appear &amp;hellip;
timeout waiting &amp;hellip;
&amp;hellip;
Then the init process crashed with kernel panic.
Solution As if it&amp;rsquo;s due to initramfs damage by the improper shutdown, so the solution is to re-generate the initramfs.
Boot from a live CD/USB Could either burn a live iso to a USB stick or mount the ISO to the server (how to mount the ISO to a server via its BMC/IPMI tools, is out of the scope).</description></item><item><title>Route setting in Multihomed Server</title><link>/posts/dual_home_ubuntu/</link><pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate><guid>/posts/dual_home_ubuntu/</guid><description>The Issue For servers with multiples interfaces connecting to differenct networks, tend to have routing issues if multiple interfaces have default route settings. For example, I have a server with two NICs, one connect to external network in subnet 10.67.126.x/23, and the other connects to internal network in subnet 192.168.8.x/24. As the DHCP servers for the two subnets both provide default route, the routing table in my server will results in multiple default routes:</description></item><item><title>SSH: Fingerprint Mismatch for Dual-boot Servers</title><link>/posts/fingerprints_for_dual_boot_system/</link><pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate><guid>/posts/fingerprints_for_dual_boot_system/</guid><description>The issue For server with multiple operating systems installed, ssh tends to fail with the fingerprints check:
$ ssh 10.67.126.129 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY! Someone could be eavesdropping on you right now (man-in-the-middle attack)! It is also possible that a host key has just been changed. The fingerprint for the ECDSA key sent by the remote host is SHA256:I4+yk7+wa9rETt+jKFZ2tEvmSecoXRsDYQc1G/f2exA.</description></item><item><title>Deploy k8s Cluster Using kubespray</title><link>/posts/deploy_k8s_cluster_using_kubespray/</link><pubDate>Sat, 25 Dec 2021 00:00:00 +0000</pubDate><guid>/posts/deploy_k8s_cluster_using_kubespray/</guid><description>Introduction Nowadays, there&amp;rsquo;re couples of way to deploy a k8s cluster in various of form factors, from experimental cluster with a single node to production deployment with hundreds of servers.
This memo is a note for deploy a &amp;lsquo;product&amp;rsquo; k8s cluster using kubespray - limited by the resources for the experiment, no dedicated storage nodes provisioned, and the networking is not covered as well.
Node Role Etcd External IP Internal IP node-101 Controller yes 192.</description></item><item><title>High Availability &amp; Load Balancing Setup</title><link>/posts/high_availability-load_balancing_setup/</link><pubDate>Wed, 22 Dec 2021 00:00:00 +0000</pubDate><guid>/posts/high_availability-load_balancing_setup/</guid><description>Introduction High availability and Load Balancing are the most important features for online services, especially for services in production.
This memo will provide a step-by-step guide for how-to setup the load balancing and High availability for an online web services. The web service used here as the experimental setup, is kubernetes api server. You could use a dummy web service hosted by nginx or httpd as well.
In this experimental setup, three servers are used</description></item></channel></rss>